{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ2fX2jNIVMl"
      },
      "outputs": [],
      "source": [
        "Programacion II"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity "
      ],
      "metadata": {
        "id": "4lpGG_tPIs2a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oJf4BkHK4WG",
        "outputId": "04543834-c6de-4aca-ccbc-270108ac4311"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"spanish\"))\n",
        "stemmer = SnowballStemmer(\"spanish\")\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = words_tokenize(text.lower())\n",
        "    tokens = [stemmer.stem(token)for token in tokens if tokrn not in stop_words]\n",
        "    return \" \". join(tokens)"
      ],
      "metadata": {
        "id": "UNkZ8Dd0R-fh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Lista de documentos preprocesados \n",
        "documents = [\"este es el primer documento\", \"este es el segundo documento\", \"y este es el tercero documento\" \"¿es este el primer documento\"]\n",
        "\n",
        "#Crear un ojeto TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "#Crear la matriz TF-IDF\n",
        "tf_idf_matrix= vectorizer.fit_transform(documents)\n",
        "\n",
        "#Obtener el vocabulario \n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "#imprimir la matriz TF-IDF\n",
        "print(tf_idf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J45EYBFtVTU6",
        "outputId": "9803b6db-3020-458f-c937-8e6059d2b03b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.42040099 0.42040099 0.42040099 0.42040099 0.54134281 0.\n",
            "  0.        ]\n",
            " [0.38161415 0.38161415 0.38161415 0.38161415 0.         0.64612892\n",
            "  0.        ]\n",
            " [0.44145838 0.44145838 0.44145838 0.44145838 0.28422902 0.\n",
            "  0.373727  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Lista de preguntas etiquetadas \n",
        "preguntas = [\"¿Como se hace un pastel?\", \"¿Que es el cambio climatico?\", \"¿Como puedo apender programacion?\", \"¿Cual es la capital de Mexico?\", \"¿Que es la energia solar?\", \"¿Cual es el mejor restaurante?\"]\n",
        "etiquetas = [\"Cosina\", \"Ciencia\" \"Programacion\", \"Geografia\", \"Ciencia\", \"Gastronomia\" ]\n",
        "\n",
        "# Dividir las preguntas en conjuntos de entrenamiento y prueba \n",
        "train_preguntas, test_preguntas, train_etiquetas, test_etiquetas = train_test_split(preguntas, etiquetas, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un objeto TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Crear la matriz TF-IDF para el conjunto de entrenamiento \n",
        "train_tf_idf_matrix = vectorizer.fit_transform(train_preguntas)\n",
        "\n",
        "# Entrenar un modelo LinearSVC\n",
        "model = LinearSVC()\n",
        "model.fit(train_tf_idf_matrix, train_etiquetas)\n",
        "\n",
        "# Crear la matriz TF-IDf para el conjunto de prueba\n",
        "test_tf_idf_matrix = vectorizer.transform(test_preguntas)\n",
        "\n",
        "# Evaluar el modelo \n",
        "accuracy = model.score(test_tf_idf_matrix, test_etiquetas)\n",
        "print(f\"La precision del modelo es: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "kKFrnb2_--OZ",
        "outputId": "ce7c9c7b-54ed-48a0-ce94-5a751264f0da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-709f5a6633d0>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Dividir las preguntas en conjuntos de entrenamiento y prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_preguntas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preguntas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_etiquetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_etiquetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreguntas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Crear un objeto TfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2559\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 5]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Definir preguntas y etiquetas \n",
        "preguntas = [\"¿Como estas?\", \"¿Que hora es?\", \"¿Como te llamas?\", \"¿Cual es la capital de Francia?\"]\n",
        "etiquetas = [\"saludos\", \"Tiempo\", \"Nombre\", \"Geografia\"]\n",
        "\n",
        "# Proesamiento \n",
        "def preprocesar (texto):\n",
        "    # Pasar todo a minusculas\n",
        "    texto = texto.lower()\n",
        "    # Quitar puntuacion\n",
        "    texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Quitar numeros \n",
        "    texto = re.sub(r'\\d+', '', texto)\n",
        "    # Quitar espacios en blanco adicionales \n",
        "    texto = \" \".join(texto.split())\n",
        "    return texto\n",
        "preguntas_procesadas = [preprocesar(pregunta) for pregunta in preguntas]\n",
        "\n",
        "# Crear matriz TF-IDF \n",
        "vectorizer = TfidfVectorizer()\n",
        "matriz_tfidf = vectorizer.fit_transform(preguntas_procesadas)\n",
        "\n",
        "# Entrenar clasificador SVM \n",
        "clf = LinearSVC()\n",
        "clf.fit(matriz_tfidf, etiquetas)\n",
        "\n",
        "# Hacer predicciones \n",
        "preguntas_nuevas = [\"¿Como se llama tu perro?\", \"¿Que dia es hoy?\", \"¿Cual es tu comida favorita?\"]\n",
        "preguntas_nuevas_procesadas = [preprocesar(pregunta) for pregunta in preguntas_nuevas]\n",
        "matriz_tfidf_nuevas = vectorizer.transform(preguntas_nuevas_procesadas)\n",
        "predicciones = clf.predict(matriz_tfidf_nuevas)\n",
        "\n",
        "# Imprimir resultados \n",
        "for pregunta, etiqueta in zip(preguntas_nuevas, predicciones):\n",
        "    print(f\"pregunta: {pregunta}\\nEtiqueta: {etiqueta}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCit0WYTTefO",
        "outputId": "86b584f7-ce25-42db-c287-6be54761782b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pregunta: ¿Como se llama tu perro?\n",
            "Etiqueta: saludos\n",
            "\n",
            "pregunta: ¿Que dia es hoy?\n",
            "Etiqueta: Tiempo\n",
            "\n",
            "pregunta: ¿Cual es tu comida favorita?\n",
            "Etiqueta: Geografia\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy.sql.expression import true\n",
        "import re \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "preguntas = [\n",
        "    \"¿Cual es el nombre del proyecto?\",\n",
        "    \"¿En que lenguaje de programacion esta escrito el proyecto?\",\n",
        "    \"¿Quienes son los desarrolladores del proyecto?\",\n",
        "    \"¿Cual es el objetivo del proyecto?\",\n",
        "    \"Cual es la licencia del proyecto?\",\n",
        "    \"¿Donde puedo encontrar mas informacion sobre el proyecto?\"\n",
        "    \n",
        "]\n",
        "\n",
        "respuestas = [\n",
        "    \"El nombre del proyecto es Chatbot en español.\",\n",
        "    \"El proyecto esta escrito en Pythom.\",\n",
        "    \"El proyecto fue desarrollado por un grupo de estudiantes de programacion\",\n",
        "    \"El objetivo del proyecto es crear un Chatbot que pueda responder preguntas frecuentes\",\n",
        "    \"El proyecto esta bajo la licencia MIT\",\n",
        "    \"Puedes encontrar mas informacion sobre el proyecto en el archivo README.md.\"\n",
        "\n",
        "]\n",
        "\n",
        "# Emtrenamiento del modelo\n",
        "vectorizer = TfidfVectorizer()\n",
        "clf = SVC(C=1)\n",
        "\n",
        "train_preguntas_preprocesadas = [re.sub('[^\\w\\s]', '', pregunta.lower()) for pregunta in preguntas]\n",
        "train_etiquetas = respuestas \n",
        "\n",
        "train_preguntas_vectorizdas = vectorizer.fit_transform(train_preguntas_preprocesadas)\n",
        "\n",
        "clf.fit (train_preguntas_vectorizdas, train_etiquetas)\n",
        "\n",
        "def responder(pregunta):\n",
        "    pregunta_preprocesada = re.sub(r'[^\\w\\s]', '', pregunta.lower())\n",
        "    pregunta_vectorizada = vectorizer.transform([pregunta_preprocesada])\n",
        "    etiqueta_predicha = clf.predict(pregunta_vectorizada)[0]\n",
        "    return etiqueta_predicha \n",
        "\n",
        "# Ejecucion del Chatbot\n",
        "while True:\n",
        "    pregunta = input('Ingresa tu pregunta: ')\n",
        "    respuesta = responder(pregunta)\n",
        "    print(respuesta)\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "1ytEVZGeihTa",
        "outputId": "514e4f5f-c8ea-40bb-c247-b23760acc066"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e8ae0306474b>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Ejecucion del Chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mpregunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ingresa tu pregunta: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mrespuesta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpregunta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrespuesta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}